{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Examples.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples: The Data Science Process\n",
    "© ExploreAI Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we explore the fundamental concepts of Univariate and Multivariate Analysis, focusing on the crucial stages of the Data Science Process. We delve into various techniques of Exploratory Data Analysis (EDA), both graphical and non-graphical, to uncover patterns and relationships within the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "\n",
    "In this train we will learn:\n",
    "- Understand the key stages of the Data Science Process and how to use it when solving problems.\n",
    "- Know how to collect, clean, and analyse data using both Univariate and Multivariate Analysis techniques.\n",
    "- Know how to apply various graphical and non-graphical methods to extract insights and identify trends.\n",
    "- Know how to interpret and communicate the results of data analysis clearly, understanding the importance of each step in making informed decisions and building robust data models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "You will learn about the **data science process**, also known as a project life cycle, in this train. You should follow this process every time you start a new data science project. Once you are familiar with the different phases of the data science process, we will hone in on one of the phases, exploring the data, and learn about **exploratory data analysis (EDA)** and the different **types** of EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sm6oc90_x5y-"
   },
   "source": [
    "## Data Science Process\n",
    "\n",
    "When you are given a data science problem to solve, the question is always: Where do I start? \n",
    "Although every problem is unique, the process we follow is not. \n",
    "The data science process is a framework we can follow to solve any data science problem.\n",
    " \n",
    "The data science process consists of the following **five phases**:\n",
    "\n",
    "<div align=\"center\" style=\"width: 500px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://github.com/Explore-AI/Pictures/blob/50f8665f1ecb715e39051574ad5f6ba8f7bbb3f2/regression_analysis_notebook/data_science_process.jpg?raw=True\"\n",
    "     alt=\"Dummy image 1\"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=500px/>\n",
    "     A Visual Guide to Standard Procedures in Data Science <a href=\"https://towardsdatascience.com/the-data-science-process-a19eb7ebc41b\">here</a>.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1:  Data Collection\n",
    "\n",
    "Data is required to help you find a solution to your data science problem. The data will provide insights that will lead you to a solution. Your data can be collected in many different ways. A company might store their data on internal databases that you need to query, or you might need to request external datasets that can be given to you in a CSV file. \n",
    "\n",
    "### Phase 2:  Data Cleaning\n",
    "\n",
    "Before doing any analysis on your data for insights, it is essential to clean the data first. Cleaning the data will ensure that you get accurate insights in the analysis phase. Cleaning your data will consist of checking for null, empty, missing and duplicated values. \n",
    "\n",
    "### Phase 3:  Exploratory Data Analysis\n",
    "\n",
    "This phase is extremely important. It helps us to understand patterns in our data, pinpoint any outliers and indicate relationships between variables. This phase includes descriptive statistics and data visualisations.\n",
    "\n",
    "### Phase 4:  Model Building\n",
    "\n",
    "In this phase, you need to select the features (variables) that will contribute to your model.  Not all features will be relevant. You will now be able to build a regression or classification model; this will include applying multiple algorithms to get the best model. Once we have decided on the best algorithm, we will train our model on the input data.\n",
    "\n",
    "Data Modelling will only be successful and make sense if you have performed data cleaning and exploratory analysis. \n",
    "\n",
    "\n",
    "### Phase 5: Model Deployment\n",
    "\n",
    "Model deployment is taking your trained model from phase 4 and making it available in a production environment. Deploying your model will make your model’s predictions on incoming data available to users or other systems.  \n",
    "\n",
    "An example of this would be Netflix making recommendations; this is based on the Netflix machine learning model using your streaming data to make predictions on what you would like to watch next. \n",
    "\n",
    "This phase is also commonly known as:  *Where the magic happens!*\n",
    "<div align=\"center\" style=\"width: 90px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://github.com/Explore-AI/Pictures/blob/f3aeedd2c056ddd233301c7186063618c1041140/regression_analysis_notebook/magic.png?raw=True\"\n",
    "     alt=\"Magic\"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=90px/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bv12xz-ZjaLD"
   },
   "source": [
    "\n",
    "\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "### Why is EDA important?\n",
    "\n",
    "Exploratory Data Analysis (EDA) helps us to understand our data without making any assumptions. EDA is a vital component before we continue with the modelling phase as it provides context and guidance on the course of action to take when developing the appropriate model. It will also assist in interpreting the results correctly. Without doing EDA you will not understand your data fully.\n",
    "\n",
    "\n",
    "### The different types of EDA\n",
    "\n",
    "EDA are generally classified in two ways:\n",
    "\n",
    "    1) Non-graphical or Graphical\n",
    "    2) Univariate or Multivariate\n",
    "    \n",
    "<div align=\"left\" style=\"width: 600px; text-align: left;\">\n",
    "<img src=\"https://github.com/Explore-AI/Pictures/blob/f860f39251c523eda779dea0140316ccbefdd8e0/eda_map.jpg?raw=True\"\n",
    "     alt=\"EDA Diagram\"\n",
    "     style=\"padding-bottom=0.5em\"\n",
    "     width=600px/>\n",
    "</div>\n",
    "\n",
    "\n",
    "#### Non-graphical EDA\n",
    "Involves calculations of summary/descriptive statistics. \n",
    "\n",
    "#### Graphical EDA\n",
    "This type of analysis will contain data visualisations.\n",
    "\n",
    "#### Univariate Analysis \n",
    "This is performed on one variable at a time as the prefix 'uni' indicates. \n",
    "\n",
    "#### Multivariate Analysis \n",
    "This type of analysis explores the relationship between two or more variables. \n",
    "When only comparing two variables it is known as **bivariate analysis** as indicated by the prefix 'bi'.\n",
    "\n",
    "Read a more detailed explanation <a href=\"https://www.stat.cmu.edu/~hseltman/309/Book/chapter4.pdf\">here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "### Example 1\n",
    "\n",
    "For a practical example, we will be looking at the Medical Claims Data. Using these four commands, we will perform a basic analysis:\n",
    "\n",
    "    - df.head()\n",
    "    - df.shape\n",
    "    - df.info()\n",
    "    - df.describe()\n",
    "    \n",
    "First, we'll import the libraries we will need, followed by the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Bolaji Joshua\\anaconda3\\Lib\\urllib\\request.py:1344\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1344\u001b[0m     h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[0;32m   1345\u001b[0m               encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Bolaji Joshua\\anaconda3\\Lib\\http\\client.py:1336\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1336\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\Bolaji Joshua\\anaconda3\\Lib\\http\\client.py:1382\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1381\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1382\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendheaders(body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\Bolaji Joshua\\anaconda3\\Lib\\http\\client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_output(message_body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\Bolaji Joshua\\anaconda3\\Lib\\http\\client.py:1091\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1091\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg)\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1094\u001b[0m \n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Bolaji Joshua\\anaconda3\\Lib\\http\\client.py:1035\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m-> 1035\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Bolaji Joshua\\anaconda3\\Lib\\http\\client.py:1477\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1475\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[1;32m-> 1477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context\u001b[38;5;241m.\u001b[39mwrap_socket(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock,\n\u001b[0;32m   1478\u001b[0m                                       server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname)\n",
      "File \u001b[1;32mc:\\Users\\Bolaji Joshua\\anaconda3\\Lib\\ssl.py:455\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    450\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    451\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    452\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msslsocket_class\u001b[38;5;241m.\u001b[39m_create(\n\u001b[0;32m    456\u001b[0m         sock\u001b[38;5;241m=\u001b[39msock,\n\u001b[0;32m    457\u001b[0m         server_side\u001b[38;5;241m=\u001b[39mserver_side,\n\u001b[0;32m    458\u001b[0m         do_handshake_on_connect\u001b[38;5;241m=\u001b[39mdo_handshake_on_connect,\n\u001b[0;32m    459\u001b[0m         suppress_ragged_eofs\u001b[38;5;241m=\u001b[39msuppress_ragged_eofs,\n\u001b[0;32m    460\u001b[0m         server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname,\n\u001b[0;32m    461\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    462\u001b[0m         session\u001b[38;5;241m=\u001b[39msession\n\u001b[0;32m    463\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Bolaji Joshua\\anaconda3\\Lib\\ssl.py:1042\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1041\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1042\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_handshake()\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Bolaji Joshua\\anaconda3\\Lib\\ssl.py:1320\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1319\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mdo_handshake()\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/regression_sprint/claims_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Bolaji Joshua\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Bolaji Joshua\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Bolaji Joshua\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\Bolaji Joshua\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Bolaji Joshua\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:728\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    725\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[1;32m--> 728\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m _get_filepath_or_buffer(\n\u001b[0;32m    729\u001b[0m     path_or_buf,\n\u001b[0;32m    730\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    731\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    732\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    733\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    734\u001b[0m )\n\u001b[0;32m    736\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    737\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32mc:\\Users\\Bolaji Joshua\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:384\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[0;32m    383\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[1;32m--> 384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urlopen(req_info) \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[0;32m    385\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    387\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Bolaji Joshua\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:289\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Bolaji Joshua\\anaconda3\\Lib\\urllib\\request.py:215\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[1;32mc:\\Users\\Bolaji Joshua\\anaconda3\\Lib\\urllib\\request.py:515\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    512\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    514\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 515\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(req, data)\n\u001b[0;32m    517\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    518\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Bolaji Joshua\\anaconda3\\Lib\\urllib\\request.py:532\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    531\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 532\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_open, protocol, protocol \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    533\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_open\u001b[39m\u001b[38;5;124m'\u001b[39m, req)\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Bolaji Joshua\\anaconda3\\Lib\\urllib\\request.py:492\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    491\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 492\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    494\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Bolaji Joshua\\anaconda3\\Lib\\urllib\\request.py:1392\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_open(http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mHTTPSConnection, req,\n\u001b[0;32m   1393\u001b[0m                         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context)\n",
      "File \u001b[1;32mc:\\Users\\Bolaji Joshua\\anaconda3\\Lib\\urllib\\request.py:1347\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1344\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[0;32m   1345\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1348\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond>"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/regression_sprint/claims_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the top five rows of our data we can see all our features as well as the types of data we are working with.\n",
    "\n",
    "Our features are:\n",
    "\n",
    "    - age\n",
    "    - sex\n",
    "    - bmi\n",
    "    - steps\n",
    "    - children\n",
    "    - smoker\n",
    "    - region\n",
    "    - insurance_claim\n",
    "    - claim_amount\n",
    "\n",
    "The types of visualisations we can create differ depending on the data type of each variable. Broadly, we need to determine whether a variable is numerical, or categorical. Currently, the `categorical` features are `sex`, `smoker`, `region` and `insurance_claim`. The `numerical` features are `age`, `bmi`, `steps`, `children` and `claim_amount`. This is confirmed by looking specifically at the data type of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape command shows us that we have **1338** rows of data and **9** features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The info command confirms our categorical and numerical features. If a feature (variable) is categorical the Dtype is **object** and if it is a numerical variable the Dtype is an **int64** or **float64**. This command also shows us that out of the 1338 none of the features contain any null values.\n",
    "\n",
    "Null values for each feature can also be checked by using the following command:\n",
    "\n",
    "    - df.isnull().sum()\n",
    "    \n",
    "This command will provide the total number of null values appearing in each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confirms that there are no null values in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "The first univariate analysis will be non-graphical. This is where we will be looking at the **descriptive statistics** of each feature. We can get the descriptive statistics of each numerical feature by using the following command:\n",
    "\n",
    "    - df.describe()\n",
    "\n",
    "This command will provide the mean, standard deviation and a five number summary of each numerical feature.\n",
    "The five number summary (Minimum, Lower Quartile (Q1) = 25%, Median (Q2) = 50%, Upper Quartile (Q3) = 75%, Maximum) is also used for creating the box plot.\n",
    "\n",
    "Individual statistical measures can also be calculated by using the following commands:\n",
    "\n",
    "    - df.count()\n",
    "    - df.mean()\n",
    "    - df.std()\n",
    "    - df.min()\n",
    "    - df.quantile([0.25, 0.5, 0.75], axis = 0)\n",
    "    - df.median()\n",
    "    - df.max()\n",
    "\n",
    "The three measures for central tendency are the mode, mean and median. The command to determine the mode is:\n",
    "\n",
    "    - df.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the statistics of a specific feature by using the same command and specifying the column.\n",
    "\n",
    "    - df.age.describe() or df['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional statistical measures that can be calculated are **kurtosis** and **skew**. \n",
    "\n",
    "Both kurtosis and skew are important statistical terms to be familiar with in data science. Kurtosis is the measure of outliers present in the data. **High kurtosis (>3)** indicates a large number of outliers and **low kurtosis (<3)** a lack of outliers.  Skew will indicate how symmetrical your data is. Below is a table that explains the range of values with regards to skew.\n",
    "\n",
    "\n",
    "|   Skew Value (x)  |       Description of Data      |\n",
    "|:-------------------|:---------------:|\n",
    "| -0.5 < x < 0.5              |Fairly Symmetrical |\n",
    "| -1 < x < -0.5 | Moderate Negative Skew  | \n",
    "| 0.5 < x < 1             | Moderate Positive Skew  | \n",
    "|       x < -1     |High Negative Skew  | \n",
    "|       x > 1  |High Positve Skew | \n",
    "\n",
    "<div align=\"left\" style=\"width: 500px; font-size: 80%; text-align: left; margin: 0 auto\">\n",
    "<img src=\"https://github.com/Explore-AI/Pictures/blob/f3aeedd2c056ddd233301c7186063618c1041140/regression_analysis_notebook/skew.jpg?raw=True\"\n",
    "     alt=\"Dummy image 1\"\n",
    "     style=\"float: left; padding-bottom=0.5em\"\n",
    "     width=500px/>\n",
    "     For a more detailed explanation on skew and kurtosis read <a href=\"https://codeburst.io/2-important-statistics-terms-you-need-to-know-in-data-science-skewness-and-kurtosis-388fef94eeaa\">here</a>.\n",
    "</div>\n",
    "\n",
    "\n",
    "The commands used to determine the skew and kurtosis of data are:\n",
    "\n",
    "    - df.skew()\n",
    "    - df.kurtosis()\n",
    "\n",
    "    Note: These functions can only operate on numerical data so we use `numeric_only=True` to automatically ignore non-numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mskew(numeric_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.skew(numeric_only=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features `age` and `bmi` are fairly symmetrical; `steps` and `children` are moderately skewed in a positive direction, and `claim_amount` is the only feature that is highly skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.kurtosis(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicates a lack of outliers for all features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "\n",
    "Now let's conduct a univariate analysis using graphical methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can look at the **distribution** of any numerical feature by using the following plots:\n",
    "\n",
    "    - histogram\n",
    "    - density plot\n",
    "    - box plot\n",
    "    - violin plot\n",
    "    \n",
    "For a categorical feature we will use a:\n",
    "\n",
    "    - bar plot\n",
    "\n",
    "#### Histogram and Density Plot\n",
    "\n",
    "For displaying a histogram and density plot we will be using the Matplotlib library and create a list of all numerical features to visualise these features at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbmi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msteps\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchildren\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclaim_amount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m# create a list of all numerical features\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df[features]\u001b[38;5;241m.\u001b[39mhist(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "features = ['age', 'bmi', 'steps', 'children', 'claim_amount'] # create a list of all numerical features\n",
    "df[features].hist(figsize=(10,10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[features].plot(kind='density', subplots=True, layout=(3, 2), sharex=False, figsize=(10, 10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that both the histogram and density plot display the same information. The density plot can be considered a smoothed version of the histogram and does not depend on the size of bins.\n",
    "\n",
    "#### Box Plot and Violin Plot\n",
    "\n",
    "For the Box Plot and Violin Plot, we will use the seaborn library and only select one feature instead of all the numerical features. We can visualise all numerical features simultaneously, but as the range of values for each feature is different, it will not create a useful visualisation. Standardisation or normalisation can be applied to a feature to adjust the range, but we will not apply it in this notebook. Further reading on standardisation and normalisation can be done <a href=\"https://medium.com/@dataakkadian/standardization-vs-normalization-da7a3a308c64\">here</a>.\n",
    "\n",
    "The `bmi` feature will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='bmi', data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='bmi', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although both the box plot and violin plot display the distribution of the data, the boxplot provides certain statistics that are useful. \n",
    "\n",
    "The five vertical lines in the boxplot provide the information of the five number summary and the dots on the right hand side of the graph is a display of outliers. The violin plot focuses more on a smoothed distribution.\n",
    "\n",
    "#### Bar Plot\n",
    "\n",
    "For the categorical features, we can create a **bar plot** to display the frequency distribution. \n",
    "\n",
    "We'll generate a bar plot of the `children` feature, where each bar represents a unique number of children from the data, and the height represents how many times that number of children occurred. This can be done by using seaborn's `countplot`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'children', data = df, palette=\"hls\")\n",
    "plt.title(\"Distribution of Children\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4\n",
    "\n",
    "Let's conduct a non-graphical multivariate analysis.\n",
    "\n",
    "For this analysis, we can determine the relationship between any two numerical features by calculating the correlation coefficient. Correlation is a measure of the degree to which two variables change together, if at all. If two features have a strong positive correlation, it means that if the value of one feature increases, the value of the other feature also increases. There are three different correlation measures:\n",
    "\n",
    "    - Pearson correlation \n",
    "    - Spearman rank correlation\n",
    "    - Kendall correlation\n",
    "\n",
    "For this lesson, we will focus on the Pearson correlation. The Pearson correlation measures the linear relationship between features and assumes that the features are normally distributed. Below is a table that explains how to interpret the Pearson correlation measure:\n",
    "\n",
    "\n",
    "|   Pearson Correlation Coefficient (r)  |       Description of Relationship     |\n",
    "|:-------------------|:---------------:|\n",
    "|  r = -1              |Perfect Negative Correlation |\n",
    "| -1 < r < -0.8 | Strong Negative Correlation  | \n",
    "| - 0.8 < r < -0.5             | Moderate Negative Correlation  | \n",
    "|       - 0.5 < r < 0     |Weak Negative Correlation  | \n",
    "|       r = 0  |No Linear Correlation | \n",
    "| 0 < r < 0.5 | Weak Positive Correlation  | \n",
    "| 0.5 < r < 0.8             | Moderate Positive Correlation  | \n",
    "|       0.8 < r < 1     |Strong Positive Correlation  | \n",
    "|       r = 1  |Perfect Positive Correlation | \n",
    "\n",
    "\n",
    "<div align=\"left\" style=\"width: 800px; text-align: left;\">\n",
    "<img src=\"https://github.com/Explore-AI/Pictures/blob/f3aeedd2c056ddd233301c7186063618c1041140/regression_analysis_notebook/pearson_corr.jpg?raw=True\"\n",
    "     alt=\"Pearson Correlation\"\n",
    "     style=\"padding-bottom=0.5em\"\n",
    "     width=800px/>\n",
    "</div>\n",
    "\n",
    "For a more detailed explanation of correlations, read <a href=\"https://medium.com/fintechexplained/did-you-know-the-importance-of-finding-correlations-in-data-science-1fa3943debc2#:~:text=Correlation%20is%20a%20statistical%20measure,to%20forecast%20our%20target%20variable.&text=It%20means%20that%20when%20the,variable(s)%20also%20increases.\">here</a>.\n",
    "\n",
    "The command we will use to determine the correlation between features is:\n",
    "\n",
    "    - df.corr()\n",
    "\n",
    "Note: This function can only operate on numerical data so we use `numeric_only=True` to automatically ignore non-numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at a two of the correlations between different features:\n",
    "\n",
    "    - age & bmi = weak positive correlation\n",
    "    - steps & bmi = moderate negative correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5\n",
    "\n",
    "Now, let's use graphical methods to conduct a multivariate analysis.\n",
    "\n",
    "For the multivariate graphical analysis the following visualisations will be considered:\n",
    "\n",
    "    - Heatmap\n",
    "    - Scatter Plot\n",
    "    - Pair Plot\n",
    "    - Joint Plot\n",
    "    - Bubble Plot\n",
    "    \n",
    "#### Heatmap\n",
    "\n",
    "The relationship between features can also be displayed graphically using a **heatmap**. The Seaborn library will be used for this basic heatmap visualisation. \n",
    "\n",
    "To see how different heatmap variations can be created, read <a href=\"https://medium.com/@szabo.bibor/how-to-create-a-seaborn-correlation-heatmap-in-python-834c0686b88e\">here</a>.\n",
    "\n",
    "The correlation coefficient value will be displayed on the heatmap using the `vmin` and `vmax` parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = sns.heatmap(df.corr(numeric_only=True), vmin=-1, vmax=1, annot=True)\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter Plot\n",
    "\n",
    "A Scatter plot is used to visualise the relationship between two different features and is most likely the primary multivariate graphical method. For this exercise, we will create a scatter plot to determine if there is a relationship between `bmi` and `age`. The parameter `hue` is set to the feature `insurance_claim`, colouring the points according to whether or not a claim was submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='age',y='bmi',hue='insurance_claim', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As indicated by the low correlation coefficient value of 0.11 and now the scatterplot, there is a very weak relationship between bmi and age.\n",
    "\n",
    "#### Pair Plot\n",
    "\n",
    "A pair plot can be used to visualise the relationships between all the numerical features at the same time. The `hue` is once again set to the feature `insurance_claim` to indicate which data points submitted an insurance claim and which didn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\");\n",
    "sns.pairplot(df, hue=\"insurance_claim\");\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joint Plot\n",
    "\n",
    "The joint plot can be used to provide univariate and multivariate analyses at the same time. The central part of the plot will be a scatter plot comparing two different features. The top and right visualisations will display the distribution of each feature as a histogram. \n",
    "\n",
    "For this joint plot, we will once again compare `age` and `bmi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x = 'age', y = 'bmi', data = df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualisation can be changed slightly by including the `hue` as `insurance_claim` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x = 'age', y = 'bmi', data = df, hue='insurance_claim');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bubble Plots\n",
    "\n",
    "A bubble plot is a variation of a scatter plot. Bubbles vary in size, dependent on another feature in the data. The same applies to the colour of the bubbles; which can be set to vary with the values of another feature. This way, we can visualise up to four dimensions/features at the same time.\n",
    "\n",
    "For this bubble plot, `bmi` and `claim_amount` will be plotted on the x-axis and y-axis, respectively. The colours of the bubbles will vary based on whether the observation is a `smoker` or not, and lastly, the size of the bubbles will vary based on the number of `children` the observation has. We will create this bubble plot by using `seaborn`’s scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.scatterplot(x=\"bmi\", \n",
    "                y=\"claim_amount\",\n",
    "                size=\"children\",\n",
    "                sizes=(20,100),\n",
    "                alpha=0.8,\n",
    "                hue=\"smoker\",\n",
    "                data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bubble plot indicates that claimants who are smokers (blue) and have higher BMIs (further right) tend to make larger insurance claims."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook provided an introductory lesson to three fundamental aspects.\n",
    "\n",
    "#### The Data Science Process\n",
    "Following the data science process is crucial for producing reliable, repeatable work. The phases are:\n",
    "- Collecting;\n",
    "- Cleaning;\n",
    "- Exploratory data analysis;\n",
    "- Model building; and\n",
    "- Model deployment.\n",
    "\n",
    "Each of these phases is integral to the data science process and should receive the required attention.\n",
    "\n",
    "#### Exploratory Data Analysis (EDA)\n",
    "Understanding the importance of exploratory data analysis and making it part of every data science project you do will make the feature and algorithm selection of phase 4 of the data science process much more manageable. It gives you a vital understanding of your data which is extremely important for building and selecting the best algorithm for your model.\n",
    "\n",
    "#### The different types of EDA\n",
    "We first break exploratory data analysis down into non-graphical and graphical analysis and then univariate and multivariate analysis. Non-graphical analysis is done by using descriptive statistics, whereas graphical analysis is done by using visualisations. In this notebook, we use the `seaborn` and `matplotlib` libraries to create visualisations, but various other tools exist for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional resources \n",
    "\n",
    "Reference these articles and notebooks for more information on this topic:\n",
    "\n",
    " - [Multivariate plotting](https://www.kaggle.com/residentmario/multivariate-plotting)\n",
    " - [Extensive Analysis + Visualisation with Python](https://www.kaggle.com/prashant111/extensive-analysis-visualization-with-python)\n",
    " - [Data Visualisation using matplotlib and seaborn](https://aaaanchakure.medium.com/data-visualization-a6dccf643fbb)\n",
    " - [Dramatically Improve Your Exploratory Data Analysis (EDA)](https://towardsdatascience.com/dramatically-improve-your-exploratory-data-analysis-eda-a2fc8c851124)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fd094b-0fee-46f1-a4b8-73766813c42b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "12_kmeans_clustering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
